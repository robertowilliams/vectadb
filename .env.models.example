# VectaDB Schema Agent - Model Configuration
# Copy this file to .env.models and configure your preferred models

# =============================================================================
# API Configuration
# =============================================================================

# Primary LLM API endpoint (default for all models)
LLM_API_BASE=http://localhost:8000

# Optional: API key if using a hosted service
# LLM_API_KEY=your-api-key-here

# VectaDB Backend URL
VECTADB_URL=http://localhost:8080

# =============================================================================
# Recommended Models for Different Use Cases
# =============================================================================

# Tier 1: Premium - Best for Complex Schema Issues
# -----------------------------------------------------------------------------

# DeepSeek V3.2 - Latest with extended context (RECOMMENDED)
# Best for: Complex errors, multi-step debugging, large schemas
# Provider: Fireworks AI
# Pricing: $0.00000056/1K prompt, $0.00000168/1K completion
DEEPSEEK_V32_MODEL=hf:deepseek-ai/DeepSeek-V3.2
DEEPSEEK_V32_API_BASE=${LLM_API_BASE}

# DeepSeek V3 - Original, proven performance
# Best for: Complex reasoning, error analysis
# Provider: Together AI
# Pricing: $0.00000125/1K tokens
DEEPSEEK_V3_MODEL=hf:deepseek-ai/DeepSeek-V3
DEEPSEEK_V3_API_BASE=${LLM_API_BASE}

# DeepSeek R1 - Advanced reasoning with chain-of-thought
# Best for: Multi-step fixes, complex transformations
# Provider: Fireworks AI
# Pricing: $0.000003/1K prompt, $0.000008/1K completion
DEEPSEEK_R1_MODEL=hf:deepseek-ai/DeepSeek-R1-0528
DEEPSEEK_R1_API_BASE=${LLM_API_BASE}

# Qwen3 235B Instruct - Best structured output
# Best for: Clean schema generation, perfect formatting
# Provider: Fireworks AI
# Pricing: $0.00000022/1K prompt, $0.00000088/1K completion
QWEN3_235B_MODEL=hf:Qwen/Qwen3-235B-A22B-Instruct-2507
QWEN3_235B_API_BASE=${LLM_API_BASE}

# Qwen3 235B Thinking - Reasoning + structured output
# Best for: Complex reasoning with clean outputs
# Provider: Together AI
# Pricing: $0.00000065/1K prompt, $0.000003/1K completion
QWEN3_235B_THINKING_MODEL=hf:Qwen/Qwen3-235B-A22B-Thinking-2507
QWEN3_235B_THINKING_API_BASE=${LLM_API_BASE}

# =============================================================================
# Tier 2: Standard - Fast and Reliable
# =============================================================================

# Llama 4 Maverick 17B - Best balance (RECOMMENDED FOR QUICK FIXES)
# Best for: Quick schema fixes, general assistance, multimodal
# Provider: Fireworks AI
# Pricing: $0.00000022/1K prompt, $0.00000088/1K completion
LLAMA4_MAVERICK_MODEL=hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
LLAMA4_MAVERICK_API_BASE=${LLM_API_BASE}

# Llama 3.3 70B - Proven reliability
# Best for: Standard validation, reliable performance
# Provider: Fireworks AI
# Pricing: $0.0000009/1K tokens
LLAMA_33_70B_MODEL=hf:meta-llama/Llama-3.3-70B-Instruct
LLAMA_33_70B_API_BASE=${LLM_API_BASE}

# =============================================================================
# Tier 3: Specialized - Domain-Specific Excellence
# =============================================================================

# Kimi K2 Thinking - Large context reasoning (262K)
# Best for: Complex reasoning, large schema analysis
# Provider: Synthetic
# Pricing: $0.00000055/1K tokens
KIMI_K2_THINKING_MODEL=hf:moonshotai/Kimi-K2-Thinking
KIMI_K2_THINKING_API_BASE=${LLM_API_BASE}

# Qwen3 Coder 480B - Code specialist
# Best for: Schema generation, JSON/YAML formatting
# Provider: Fireworks AI
# Pricing: $0.00000045/1K prompt, $0.0000018/1K completion
QWEN3_CODER_MODEL=hf:Qwen/Qwen3-Coder-480B-A35B-Instruct
QWEN3_CODER_API_BASE=${LLM_API_BASE}

# =============================================================================
# Tier 4: Budget - Cost-Effective Options
# =============================================================================

# GLM 4.7 - Lightweight and fast (RECOMMENDED FOR TESTING)
# Best for: Simple validation, quick fixes, large context (202K)
# Provider: Synthetic
# Pricing: $0.00000055/1K prompt, $0.00000219/1K completion
GLM_47_MODEL=hf:zai-org/GLM-4.7
GLM_47_API_BASE=${LLM_API_BASE}

# MiniMax M2 - Ultra cheap
# Best for: High-volume testing, budget constraints
# Provider: Fireworks AI
# Pricing: $0.0000003/1K prompt, $0.0000012/1K completion
MINIMAX_M2_MODEL=hf:MiniMaxAI/MiniMax-M2
MINIMAX_M2_API_BASE=${LLM_API_BASE}

# GPT-OSS-120B - Extremely cheap OpenAI-like
# Best for: Experimentation, high-volume testing
# Provider: Fireworks AI
# Pricing: $0.0000001/1K tokens
GPT_OSS_MODEL=hf:openai/gpt-oss-120b
GPT_OSS_API_BASE=${LLM_API_BASE}

# =============================================================================
# Default Model Selection
# =============================================================================

# Set your default model here (used when --model is not specified)
# Options: deepseek-v3.2, deepseek-v3, deepseek-r1, qwen3-235b, qwen3-235b-thinking,
#          llama4-maverick, llama-3.3-70b, kimi-k2-thinking, qwen3-coder,
#          glm-4.7, minimax-m2, gpt-oss-120b

DEFAULT_MODEL=deepseek-v3.2

# =============================================================================
# Usage Examples
# =============================================================================

# Using environment variables with the agent:
#
# 1. Load config from environment:
#    python vectadb_schema_agent.py --model deepseek-v3.2 --schema-file bedrock_schema.json
#
# 2. Override API base:
#    LLM_API_BASE=http://remote-server:8000 python vectadb_schema_agent.py --model qwen3-235b
#
# 3. Use default model:
#    python vectadb_schema_agent.py --schema-file bedrock_schema.json
#
# 4. Interactive mode:
#    python vectadb_schema_agent.py --model llama4-maverick --interactive

# =============================================================================
# Model Selection Guide
# =============================================================================

# For Bedrock Log Schema:
# -----------------------
# Primary:   deepseek-v3.2  (best reasoning, extended context)
# Backup:    qwen3-235b     (best formatting)
# Fast:      llama4-maverick (quick iterations)
# Testing:   glm-4.7        (cheap, fast)

# For Complex Multi-File Schemas:
# --------------------------------
# Primary:   deepseek-r1    (advanced reasoning)
# Backup:    qwen3-235b-thinking (reasoning + formatting)

# For Code/JSON Generation:
# --------------------------
# Primary:   qwen3-coder    (specialized for code)
# Backup:    qwen3-235b     (excellent JSON)

# For Budget-Conscious Development:
# ----------------------------------
# Testing:   glm-4.7        (fast, cheap)
# Volume:    minimax-m2     (ultra cheap)
# Experiment: gpt-oss-120b  (extremely cheap)

# =============================================================================
# Performance Tips
# =============================================================================

# 1. Use DeepSeek V3.2 or Qwen3-235B for first-time schema fixes
# 2. Use Llama4-Maverick for iterative development
# 3. Use GLM-4.7 for quick validation checks
# 4. Use Qwen3-Coder when generating schemas from code
# 5. Use Kimi K2 when dealing with very large contexts

# =============================================================================
# Cost Optimization
# =============================================================================

# Cheapest to Most Expensive (per 1M tokens):
# 1. GPT-OSS-120B:     $0.10
# 2. MiniMax M2:       $0.30-$1.20
# 3. Llama 3.3 70B:    $0.90
# 4. DeepSeek V3.2:    $0.56-$1.68
# 5. GLM-4.7:          $0.55-$2.19
# 6. Llama4-Maverick:  $0.22-$0.88
# 7. Qwen3-235B:       $0.22-$0.88
# 8. Qwen3-Coder:      $0.45-$1.80
# 9. DeepSeek V3:      $1.25
# 10. DeepSeek R1:     $3.00-$8.00
